% Section 4: Model 1 - Medal Forecasting (PCA-LSTM-XGBoost)
% 模型一：奖牌预测模型（任务1核心）

\section{Model 1: Medal Forecasting via PCA--LSTM--XGBoost}
\label{sec:model1}

% 4.1 数据描述与预处理
\subsection{Data Description \& Preprocessing}
\label{subsec:model1_data}

We compile a comprehensive dataset spanning 1896--2024 Olympic records, encompassing:
\begin{itemize}[itemsep=0.2em]
    \item \textbf{Event-level features:} Historical medal counts by sport, event participation rates, and athlete demographics.
    \item \textbf{Macro-level covariates:} GDP per capita, population, sports funding indices, and host-country indicators.
\end{itemize}

\noindent\textbf{Missing Value Imputation.} We apply multiple imputation by chained equations (MICE) for sporadic missingness and forward-fill for time-series gaps.

\noindent\textbf{Normalization.} All continuous features are standardized via Z-score transformation to ensure comparable scales across heterogeneous indicators.

% 4.2 模型构建
\subsection{Model Formulation}
\label{subsec:model1_formulation}

We fuse heterogeneous predictors through a two-stage representation learning scheme: PCA for denoising and compression, followed by LSTM for temporal encoding.

\subsubsection{PCA Dimensionality Reduction}
Let $\mathbf{x}_{i,t} \in \mathbb{R}^{p}$ denote the standardized feature vector for NOC $i$ at cycle $t$. PCA projects $\mathbf{x}_{i,t}$ to a $k$-dimensional score vector:
\begin{equation}
    \label{eq:pca_projection}
    \mathbf{z}_{i,t} = \mathbf{W}^{\top}\mathbf{x}_{i,t},\qquad \mathbf{W}\in\mathbb{R}^{p\times k}.
\end{equation}

\subsubsection{LSTM Temporal Encoding}
Given a look-back window length $L$, we form an input sequence $\mathbf{Z}_{i,t} = (\mathbf{z}_{i,t-L+1},\ldots,\mathbf{z}_{i,t})$ and encode it with an LSTM:
\begin{equation}
    \label{eq:lstm_encoding}
    \mathbf{h}_{i,t} = \mathrm{LSTM}(\mathbf{Z}_{i,t};\,\Theta_{\mathrm{LSTM}}),
\end{equation}
where $\mathbf{h}_{i,t}$ summarizes the latent performance trajectory of NOC $i$ up to time $t$.

\subsubsection{Feature Fusion}
We construct a fused representation by concatenating the temporal embedding with structured covariates:
\begin{equation}
    \label{eq:feature_fusion}
    \mathbf{f}_{i,t} = \big[\,\mathbf{h}_{i,t};\,\mathrm{Host}_{i,t};\,\mathbf{u}_{i,t}\,\big].
\end{equation}

% 4.3 求解算法
\subsection{Solution Algorithm}
\label{subsec:model1_algorithm}

A downstream gradient-boosting regressor (XGBoost) maps $\mathbf{f}_{i,t}$ to medal predictions, and bootstrap resampling quantifies the 95\% predictive interval.

\begin{algorithm}[H]
    \caption{PCA--LSTM--XGBoost Training Pipeline}
    \label{alg:pcalstm_train}
    \DontPrintSemicolon
    \SetAlgoLined
    \KwIn{Historical dataset $\{(\mathbf{x}_{i,t}, M_{i,t})\}$; PCA dimension $k$; window $L$; bootstrap size $\mathcal{B}$}
    \KwOut{Predictor $\hat{M}_{i,t}$ and 95\% interval $\mathrm{CI}^{95\%}_{i,t}$}
    \BlankLine
    Standardize features; fit PCA to obtain $\mathbf{W}$; compute $\mathbf{z}_{i,t}=\mathbf{W}^\top\mathbf{x}_{i,t}$\;
    Build sequences $\mathbf{Z}_{i,t}=(\mathbf{z}_{i,t-L+1},\ldots,\mathbf{z}_{i,t})$\;
    Train LSTM to learn $\Theta_{\mathrm{LSTM}}$; extract $\mathbf{h}_{i,t}$\;
    Form $\mathbf{f}_{i,t}=[\mathbf{h}_{i,t};\,\mathrm{Host}_{i,t};\,\mathbf{u}_{i,t}]$\;
    \For{$b\gets 1$ \KwTo $\mathcal{B}$}{
        Resample training pairs; train XGBoost $g^{(b)}(\cdot)$\;
        Predict $\hat{M}^{(b)}_{i,t}\gets g^{(b)}(\mathbf{f}_{i,t})$\;
    }
    Set $\hat{M}_{i,t}$ as mean and $\mathrm{CI}^{95\%}_{i,t}$ as 2.5\%--97.5\% quantiles\;
\end{algorithm}

% 4.4 结果与解读
\subsection{Results \& Interpretation}
\label{subsec:model1_results}

% 【提示】此处插入预测结果图表
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \fbox{\parbox[c][0.22\textheight][c]{\textwidth}{\centering\textbf{(a) 2024 Actual vs. 2028 Forecast}\par\vspace{0.5em}\small Replace with grouped bar chart.}}
        \caption{Actual vs. forecast comparison}
        \label{fig:model1_bar}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \fbox{\parbox[c][0.22\textheight][c]{\textwidth}{\centering\textbf{(b) 95\% Prediction Interval}\par\vspace{0.5em}\small Replace with shaded CI plot.}}
        \caption{Uncertainty quantification}
        \label{fig:model1_ci}
    \end{subfigure}
    \caption{Medal forecasting results for Model 1.}
    \label{fig:model1_results}
\end{figure}

The model achieves low MAE and MAPE on held-out test sets, indicating strong out-of-sample stability. The 95\% confidence intervals provide actionable uncertainty bounds for NOC planning.
