% Section 8: Model Evaluation

\section{Model Evaluation}
\label{sec:evaluation}

We evaluate our framework via internal consistency checks, case studies, and computational efficiency.

\subsection{Internal Consistency}
\begin{itemize}[itemsep=0.1em]
    \item \textbf{Posterior validity:} 100\% of posterior means lie within their LP/MILP intervals.
    \item \textbf{Uncertainty scale:} mean HDI width = 0.239; median HDI width = 0.268.
    \item \textbf{Coverage:} 2,250 contestant-week posteriors across 264 elimination weeks.
\end{itemize}

\subsection{Case Study: Bobby Bones (S27)}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{figures/bobby_bones_survival.png}
    \caption{\textbf{Bobby Bones Posterior Fan Vote.} The 95\% HDI remains wide (max width $\approx 0.46$), highlighting structural underidentification in the 50/50 system.}
    \label{fig:bobby_survival}
\end{figure}

\noindent\textbf{Interpretation.} Even after Bayesian smoothing, the interval remains broad---a low judge-score contestant can survive with a wide range of fan support. This motivates shifting weight toward judges early in the season.

\subsection{Computational Efficiency}
The end-to-end pipeline completes within a few minutes on a laptop for 2,000 MCMC samples per week. LP/MILP inversion remains sub-second per week, enabling pre-broadcast diagnostics.
