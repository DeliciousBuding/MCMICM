% Section 8: Model Evaluation
% 模型评估

\section{Model Evaluation}
\label{sec:evaluation}

We evaluate our framework across consistency, external validation, and efficiency.

\subsection{Internal Consistency}

\begin{itemize}[itemsep=0.1em]
    \item \textbf{100\%} of point estimates lie within computed bounds $[v_i^{\min}, v_i^{\max}]$.
    \item Median week-to-week change: $|\hat{v}_{i,w} - \hat{v}_{i,w-1}| = 3.2\%$; autocorrelation $\rho = 0.71$.
\end{itemize}

\subsection{External Validation}

Correlation with social media (47 contestants with data): Instagram followers $r = 0.52$, Twitter engagement $r = 0.41$ ($p < 0.01$), suggesting inferred votes capture genuine popularity.

\begin{table}[H]
    \centering
    \caption{Anomaly Detection vs.\ Known Controversies}
    \label{tab:anomaly_validation}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Season} & \textbf{Our Flag} & \textbf{Public Controversy} & \textbf{Match} \\
        \midrule
        S30 & Normal & Mild complaints & \checkmark \\
        S32 & \textbf{Anomaly} & Major backlash & \checkmark \\
        S33 & \textbf{Anomaly} & Voting irregularity reports & \checkmark \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Comparison with Alternatives}

\begin{table}[H]
    \centering
    \caption{Model Comparison}
    \label{tab:model_comparison}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Approach} & \textbf{Violation Rate} & \textbf{C-index} \\
        \midrule
        Naive uniform & 73\% & 0.50 \\
        Judge-only regression & 28\% & 0.61 \\
        \textbf{Our LP/CP} & \textbf{0\%} & \textbf{0.72} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Computational Efficiency}

Total runtime: \textbf{19.8 sec} on standard laptop (i7, 16GB RAM), comprising data loading (2.3s), LP (8.7s), CP (1.2s), survival analysis (3.5s), and simulation (4.1s).
